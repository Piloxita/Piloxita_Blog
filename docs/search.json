[
  {
    "objectID": "posts/Option_trading/index.html",
    "href": "posts/Option_trading/index.html",
    "title": "Predicting Stock Price Movements on Earnings Announcements Using Machine Learning",
    "section": "",
    "text": "Introduction\nIt started like many trading days before—a quiet anticipation as I scrolled through earnings reports, scanning for opportunities. But this time, something clicked. Over the years, I’d noticed a recurring pattern: earnings announcements often sent stock prices soaring or tumbling. These fleeting moments held immense potential for profit.\nDriven by curiosity, I asked myself: could machine learning—with its ability to uncover hidden patterns in data—help predict the magnitude of these price movements? Armed with a passion for data and a love for strategy, I set out to merge technology and trading. This blog captures my journey.\n\n\nFolder and Environment Setup\nBefore jumping into the data, I made sure to set up an efficient and organized working environment. Here’s a simple setup to get you started:\n\nPlace your Excel file and Jupyter Notebook in the same folder.\nFor a complete project structure, I recommend this helpful guide.\n\nPython Environment: Use a virtual environment to ensure consistency:\n\nCreate a virtual environment using conda env create --name &lt;env name&gt;.\n\nActivate the environment (conda activate &lt;env name&gt;).\n\nInstall the necessary packages, such as pandas, numpy, scikit-learn, lightgbm, xgboost, and catboost.\nNote: you can find my environment.yml file in my github repo to set up a completely similar environment for this project.\n\nVersion Control: Use Git for version control to track changes in your project.\nThis setup ensures that your workflow is clean, reproducible, and scalable as the project evolves.\n\n\nCollecting and Storing Data\nEvery story needs a foundation, and in this case, it’s data. To predict stock price movements, I needed to gather the right ingredients:\n\nTechnical Patterns: Indicators like moving averages and resistance/support levels that reveal market trends.\nSentiment Indicators: The put/call ratio, a barometer of market sentiment during earnings seasons.\nHistorical Earnings Movements: Data on how stock prices reacted to past earnings announcements.\n\nI compiled these features in an Excel file, structured for easy analysis. Remember to save your file in the same directory as your notebook.\n\n\n\nFigure 1: My excel file with pandas-friendly labels\n\n\n\n\n\nFigure 2: My excel file with pandas-friendly labels (cont)\n\n\nSome of this data, like call/put options and momentum grades, may require a subscription. You can explore options data on Seeking Alpha or stock data on TradingView.\n\n\nInput and Clean Data\nOnce my data was in place, the next step was to clean and prepare it for analysis. This is where the real magic happens:\n\nImporting Libraries\n\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\n\nImporting Data: Using Python’s pandas library to read the Excel file into a structured format.\n\ndf = pd.read_excel('open interest.xlsx')\ndf.tail()\n\n\n\nFigure 3: Read excel to panda dataframe\n\n\n\nSplit Dataset to Train and Test set: This is to make sure there is no data leakage happening in the training process\n\ntrain_df, test_df = train_test_split(df, test_size=0.1, random_state=123)\n\nX_train = train_df.drop('Day_after_earning_gain_loss', axis = 1)\ny_train = train_df['Day_after_earning_gain_loss']\nX_test = test_df.drop('Day_after_earning_gain_loss', axis = 1)\ny_test = test_df['Day_after_earning_gain_loss']\n\nPreprocessing\n\n\nDrop Irrelevant Columns: Remove columns like Date and Ticker that do not add value to the predictive model.\nOne-Hot Encoding: Convert categorical variables such as Weekday, Industry, and Revenue_source into numerical representations.\nOrdinal Encoding: Transform ordinal features, such as Momentum_Grade, based on a predefined category order.\nPass-through Features: Allow numerical columns that require no transformation to pass through unchanged.\n\nHere’s a Python snippet illustrating the preprocessing pipeline:\ndrop_columns = ['Date', 'Ticker']\none_hot_columns = ['Weekday', 'Industry', 'Revenue_source']\nordinal_columns = ['Momentum_Grade']\npass_through_columns = list(set(X_train.columns) - set(drop_columns + one_hot_columns + ordinal_columns + ['Day_after_earning_gain_loss']))\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('drop', 'drop', drop_columns),\n        ('onehot', OneHotEncoder(handle_unknown='ignore'), one_hot_columns),\n        ('ordinal', OrdinalEncoder(categories=[momentum_grade_order]), ordinal_columns),\n        ('passthrough', 'passthrough', pass_through_columns)\n    ]\n)\nData preparation might seem tedious, but it’s the unsung hero of any successful machine learning project. Without clean data, even the best algorithms can falter.\n\n\nTraining Models\nWith my data prepped, it was time to bring in the heavy hitters: LightGBM, XGBoost, and CatBoost. These ensemble models are like a dream team for structured financial data, each bringing unique strengths to the table.\n\nLightGBM: Lightning-fast and efficient for handling large datasets.\nXGBoost: Renowned for precision and adaptability.\nCatBoost: A natural choice for datasets with categorical variables.\n\nHowever, with a limited dataset, I faced a tough decision: should I fine-tune the models or stick with their default settings? To avoid overfitting, I chose the latter, focusing on creating a balanced baseline instead. Here’s a snippet of how I trained the models:\nfrom sklearn.ensemble import VotingRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\n\nlgbm = LGBMRegressor()\nxgb = XGBRegressor(verbosity=0)\ncatboost = CatBoostRegressor(verbose=0)\n\nensemble_model = VotingRegressor(estimators=[\n    ('lgbm', lgbm),\n    ('xgb', xgb),\n    ('catboost', catboost)\n])\n\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', ensemble_model)\n])\n\n\nMaking Predictions and Setting Up a Trade\npipeline.predict(X_test)\nThe output is 0.055 and -0.03. This predicts one of the stock price movement after earning announcement is +5.5% and the other one’s is -3%. However, the actual movement of these stocks (which are PLTR and MARA) was +23.47% and -13.99%.\nIf you want to predict other stocks, just create a dataframe with the same format as your X_test and feed it to pipeline.predict().\nExecuting the Straddle Strategy: The predictions suggested small price movements, making the straddle strategy unsuitable for this scenario.\n\n\nConclusion\nLooking back, this journey was as much about discovery as it was about trading. Here’s what I learned:\n\nKey Takeaways: Machine learning has immense potential in options trading, offering insights that were once hidden in the noise of the market.\nLimitations: My small dataset and lack of hyperparameter tuning left room for improvement. But every limitation is an invitation to grow.\nPotential: With more data and fine-tuning, this approach could become a game-changer for traders worldwide.\nDisclaimer: This analysis is educational and should not be considered financial advice.\n\n\nTrading is as much an art as it is a science. By combining a tried-and-tested strategy with cutting-edge machine learning, I’ve uncovered a new way to approach the market. The question is: are you ready to explore it for yourself?\nYou can find my code and dataset here"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog is to tell you my journey of how I blend finance and data science to come up with something useful!!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PILOXITA’s Blog",
    "section": "",
    "text": "Predicting Stock Price Movements on Earnings Announcements Using Machine Learning\n\n\n\n\n\n\nnews\n\n\ntrading\n\n\nmachine learning\n\n\n\n\n\n\n\n\n\nJan 15, 2025\n\n\nLong Nguyen\n\n\n\n\n\n\nNo matching items"
  }
]